diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/MagpieNetworkFileSystem.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/MagpieNetworkFileSystem.java
new file mode 100644
index 0000000..1d10013
--- /dev/null
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/MagpieNetworkFileSystem.java
@@ -0,0 +1,188 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.fs;
+
+import java.io.BufferedOutputStream;
+import java.io.DataOutput;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileNotFoundException;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.io.FileDescriptor;
+import java.net.URI;
+import java.nio.ByteBuffer;
+import java.util.Arrays;
+import java.util.EnumSet;
+import java.util.StringTokenizer;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.permission.FsPermission;
+import org.apache.hadoop.io.nativeio.NativeIO;
+import org.apache.hadoop.util.Progressable;
+import org.apache.hadoop.util.Shell;
+import org.apache.hadoop.util.StringUtils;
+import org.apache.hadoop.fs.RawLocalFileSystem;
+import org.apache.hadoop.fs.RawLocalFileSystem.RawLocalFileStatus;
+
+public class MagpieNetworkFileSystem extends RawLocalFileSystem {
+  public static final URI NAME = URI.create("magpienetworkfs:///");
+  private String base_dir = null;  
+  
+  public MagpieNetworkFileSystem() {
+    super();
+  }
+  
+  private Path pathWithBase(Path f) {
+    if (f != null && !f.isAbsolute() && base_dir != null) {
+	return new Path(base_dir, f);
+    }  
+    return f;
+  }
+
+  @Override
+  public URI getUri() { return NAME; }
+  
+  @Override
+  public void initialize(URI uri, Configuration conf) throws IOException {
+    super.initialize(uri, conf);
+    setConf(conf);
+    base_dir = conf.get("fs.magpienetworkfs.base.dir");
+    if (base_dir != null) {
+	setWorkingDirectory(new Path(base_dir));
+    }
+  }
+
+  @Override
+  public FSDataInputStream open(Path f, int bufferSize) throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.open(ftmp, bufferSize);
+  }
+  
+  @Override
+  public FSDataOutputStream append(Path f, int bufferSize,
+      Progressable progress) throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.append(ftmp, bufferSize, progress);
+  }
+
+  @Override
+  public FSDataOutputStream create(Path f, boolean overwrite, int bufferSize,
+    short replication, long blockSize, Progressable progress)
+    throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.create(ftmp, overwrite, bufferSize, replication, blockSize, progress);
+  }
+
+  @Override
+  @Deprecated
+  public FSDataOutputStream createNonRecursive(Path f, FsPermission permission,
+      EnumSet<CreateFlag> flags, int bufferSize, short replication, long blockSize,
+      Progressable progress) throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.createNonRecursive(ftmp, permission, flags, bufferSize, replication, blockSize, progress); 
+  }
+
+  @Override
+  public FSDataOutputStream create(Path f, FsPermission permission,
+    boolean overwrite, int bufferSize, short replication, long blockSize,
+    Progressable progress) throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.create(ftmp, permission, overwrite, bufferSize, replication, blockSize, progress);
+  }
+
+  @Override
+  public FSDataOutputStream createNonRecursive(Path f, FsPermission permission,
+      boolean overwrite,
+      int bufferSize, short replication, long blockSize,
+      Progressable progress) throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.createNonRecursive(ftmp, permission, overwrite, bufferSize, replication, blockSize, progress);
+  }
+
+  @Override
+  public boolean rename(Path src, Path dst) throws IOException {
+    Path srctmp = pathWithBase(src);
+    Path dsttmp = pathWithBase(dst);
+    return super.rename(srctmp, dsttmp);
+  }
+  
+  @Override
+  public boolean delete(Path p, boolean recursive) throws IOException {
+    Path ptmp = pathWithBase(p);
+    return super.delete(ptmp, recursive); 
+  }
+ 
+  @Override
+  public FileStatus[] listStatus(Path f) throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.listStatus(ftmp);
+  }
+
+  @Override
+  public boolean mkdirs(Path f) throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.mkdirs(ftmp); 
+  }
+
+  @Override
+  public boolean mkdirs(Path f, FsPermission permission) throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.mkdirs(ftmp, permission); 
+  }
+
+  @Override
+  protected boolean primitiveMkdir(Path f, FsPermission absolutePermission)
+    throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.mkdirs(ftmp, absolutePermission); 
+  }
+
+  @Override
+  protected Path getInitialWorkingDirectory() {
+    if (base_dir == null) {
+      return this.makeQualified(new Path(System.getProperty("user.dir")));
+    }
+    else {
+      return new Path(base_dir);
+    }
+  }
+  
+  @Override
+  public long getDefaultBlockSize() {
+    return getConf().getLong("fs.magpienetworkfs.block.size", 32 * 1024 * 1024);
+  }
+
+  @Override
+  public long getDefaultBlockSize(Path f) {
+    return getDefaultBlockSize();
+  }
+
+  @Override
+  public FsStatus getStatus(Path p) throws IOException {
+    Path ptmp = pathWithBase(p);
+    return super.getStatus(ptmp); 
+  }
+  
+  @Override
+  public String toString() {
+    return "MagpieNetworkFS";
+  }
+}
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java
index e27a227..cb1b475 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/RawLocalFileSystem.java
@@ -562,7 +562,7 @@ public String getGroup() {
     private void loadPermissionInfo() {
       IOException e = null;
       try {
-        String output = FileUtil.execCommand(new File(getPath().toUri()), 
+        String output = FileUtil.execCommand(new File(getPath().toUri().getPath()), 
             Shell.getGetPermissionCommand());
         StringTokenizer t =
             new StringTokenizer(output, Shell.TOKEN_SEPARATOR_REGEX);
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/RawLocalFs.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/RawLocalFs.java
index edcebcb..b7266bc 100644
--- a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/RawLocalFs.java
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/local/RawLocalFs.java
@@ -28,6 +28,7 @@
 import org.apache.hadoop.fs.AbstractFileSystem;
 import org.apache.hadoop.fs.DelegateToFileSystem;
 import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileSystem;
 import org.apache.hadoop.fs.FsConstants;
 import org.apache.hadoop.fs.FsServerDefaults;
 import org.apache.hadoop.fs.Path;
@@ -62,6 +63,12 @@
         FsConstants.LOCAL_FS_URI.getScheme(), false);
   }
   
+  protected RawLocalFs(URI theUri, FileSystem theFsImpl,
+		       Configuration conf, String supportedScheme, boolean authorityRequired)
+      throws IOException, URISyntaxException {
+    super(theUri, theFsImpl, conf, supportedScheme, authorityRequired);
+  }
+
   @Override
   public int getUriDefaultPort() {
     return -1; // No default port for file:///
diff --git a/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/magpienetworkfs/MagpieNetworkFs.java b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/magpienetworkfs/MagpieNetworkFs.java
new file mode 100644
index 0000000..4785faf
--- /dev/null
+++ b/hadoop-common-project/hadoop-common/src/main/java/org/apache/hadoop/fs/magpienetworkfs/MagpieNetworkFs.java
@@ -0,0 +1,93 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.fs.magpienetworkfs;
+
+import java.io.FileNotFoundException;
+import java.io.IOException;
+import java.net.URI;
+import java.net.URISyntaxException;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.AbstractFileSystem;
+import org.apache.hadoop.fs.DelegateToFileSystem;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FsConstants;
+import org.apache.hadoop.fs.FsServerDefaults;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.MagpieNetworkFileSystem;
+import org.apache.hadoop.fs.permission.FsPermission;
+import org.apache.hadoop.fs.local.RawLocalFs;
+import org.apache.hadoop.fs.local.LocalConfigKeys;
+import org.apache.hadoop.util.Shell;
+import org.apache.commons.logging.Log;
+import org.apache.commons.logging.LogFactory;
+
+public class MagpieNetworkFs extends RawLocalFs {
+  private String base_dir = null;
+
+  private static final Log LOG = LogFactory.getLog(MagpieNetworkFs.class);
+
+  private Path pathWithBase(Path f) {
+    if (f != null && !f.isAbsolute() && base_dir != null) {
+	return new Path(base_dir, f);
+    }  
+    return f;
+  }
+
+  MagpieNetworkFs(final Configuration conf) throws IOException, URISyntaxException {
+    this(MagpieNetworkFileSystem.NAME, conf);
+    base_dir = conf.get("fs.magpienetworkfs.base.dir");
+  }
+  
+  /**
+   * This constructor has the signature needed by
+   * {@link AbstractFileSystem#createFileSystem(URI, Configuration)}.
+   * 
+   * @param theUri which must be that of localFs
+   * @param conf
+   * @throws IOException
+   * @throws URISyntaxException 
+   */
+  MagpieNetworkFs(final URI theUri, final Configuration conf) throws IOException,
+      URISyntaxException {
+    super(theUri, new MagpieNetworkFileSystem(), conf, 
+	  MagpieNetworkFileSystem.NAME.getScheme(), false);
+    base_dir = conf.get("fs.magpienetworkfs.base.dir");
+  }
+  
+  @Override
+  public void createSymlink(Path target, Path link, boolean createParent) 
+      throws IOException {
+    final String targetScheme = target.toUri().getScheme();
+    if (targetScheme != null
+	&& !"file".equals(targetScheme)
+	&& !"magpienetworkfs".equals(targetScheme)) {
+      throw new IOException("Unable to create symlink to non-local file "+
+                            "system: "+target.toString());
+    }
+    Path targettmp = pathWithBase(target);
+    Path linktmp = pathWithBase(link);
+    super.createSymlink(targettmp, linktmp, createParent);
+  }
+
+  @Override
+  public FileStatus getFileLinkStatus(final Path f) throws IOException {
+    Path ftmp = pathWithBase(f);
+    return super.getFileLinkStatus(ftmp);
+  }
+}
