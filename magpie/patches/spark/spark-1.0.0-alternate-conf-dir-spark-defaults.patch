From 97db4c4b0d0363c7556233673e408d160cd5ed88 Mon Sep 17 00:00:00 2001
From: Albert Chu <chu11@llnl.gov>
Date: Wed, 11 Jun 2014 16:15:46 -0700
Subject: [PATCH] SPARK-2116: If SPARK_CONF_DIR environment variable is set, search it for spark-defaults.conf.


Signed-off-by: Albert Chu <chu11@llnl.gov>
---
 .../apache/spark/deploy/SparkSubmitArguments.scala |   11 +++++++++++
 1 files changed, 11 insertions(+), 0 deletions(-)

diff --git a/core/src/main/scala/org/apache/spark/deploy/SparkSubmitArguments.scala b/core/src/main/scala/org/apache/spark/deploy/SparkSubmitArguments.scala
index 153eee3..30a0285 100644
--- a/core/src/main/scala/org/apache/spark/deploy/SparkSubmitArguments.scala
+++ b/core/src/main/scala/org/apache/spark/deploy/SparkSubmitArguments.scala
@@ -83,6 +83,17 @@ private[spark] class SparkSubmitArguments(args: Seq[String]) {
 
     // Use common defaults file, if not specified by user
     if (propertiesFile == null) {
+      sys.env.get("SPARK_CONF_DIR").foreach { sparkConfDir =>
+        val sep = File.separator
+        val defaultPath = s"${sparkConfDir}${sep}spark-defaults.conf"
+        val file = new File(defaultPath)
+        if (file.exists()) {
+          propertiesFile = file.getAbsolutePath
+        }
+      }
+    }
+
+    if (propertiesFile == null) {
       sys.env.get("SPARK_HOME").foreach { sparkHome =>
         val sep = File.separator
         val defaultPath = s"${sparkHome}${sep}conf${sep}spark-defaults.conf"
-- 
1.7.1

